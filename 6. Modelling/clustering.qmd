---
title: "Clustering"
format: html
editor: visual
---

## Clustering

The modelling is composed of two stages. As a first step, electorates will be clustered, which will be used as an additional variable for a regression/interpretation model.

The last election will be removed from training data - it will be used as validation later .

Clustering will attempt to identify similar electorates from a demopgrahic PoV.

Once removed the 2022 data, the clustering won't make any distiction betwen the years:

-   the period covered is relatively short to experience signigicant demographic and social changes.

-   Taken this into account, we will assume that demdemographicopgrahic changes are more relevant than time changes.

```{r setup}

library(tidyverse)
library(aussiemaps)
library(dbscan)
library(FactoMineR)
library(factoextra)
library(here)
library(glue)
library(gt)
```

## load data, excluding 2021

```{r load}

parties <- c("ALP","COAL","GRN","Other")

dataset <- read_csv(here("4. Data","consolidated.csv")) |>
          select(-any_of(parties))


train <- dataset |> filter(election_year!=2022) 
test  <- dataset |> filter(election_year==2022)

```

create clustering set, create groups for MFA

```{r}

train_clustering <- train |>
                    mutate(Division = glue("{DivisionNm}_{election_year}"),
                           .keep = "unused")

groups <- colnames( train_clustering |>
                    select(-any_of(c("StateAb","Metro_Area",
                                     "Year","Division")),
                    -any_of(parties))) |>
          as_tibble() |>
          mutate(group=case_when(
            str_detect(value,"_") ~  str_extract(value, "^([^_]+)"),
            TRUE ~ value
          )) 

group_order <- distinct(groups,group) |> mutate(order=row_number())

groups <- groups|>
  group_by(group) |>
  summarise(n=n(),.groups="drop") |>
  left_join(group_order,by="group") |>
  arrange(order)

```

MFA

```{r}
transform_pred <- MFA(train_clustering |>
                       select(-any_of(c("StateAb","Metro_Area","Year")),
                              -any_of(parties)) |>
                       remove_rownames() |>
                       column_to_rownames(var="Division"),
                       group=groups$n,
                       ncp=10,
                       type=c(rep("c",8),"n"),
                       name.group =groups$group,
                       graph=FALSE)
```

```{r}
fviz_screeplot(transform_pred)
```

```{r}
transform_pred$eig |> 
  as_tibble() |>
  mutate(Dimension=glue("Dim {row_number()}"), .before=1) |>
  gt()
```

```{r}
fviz_mfa_var(transform_pred)
```

No clearly interpretable dimensions but:

-   made them more orthogonal

-   redcuded the number of variables

#### clustering using dbscan

#### step 1: calculate en plot knn distances to determine epsilon

```{r}
kNNdistplot(transform_pred$ind$coord,5)
```

```{r}
clustering <- dbscan(transform_pred$ind$coord,2.5,minPts = 40)

```

```{r}
```

```{r}

clustering <- dbscan::hdbscan(transform_pred$ind$coord,30,gen_hdbscan_tree=TRUE)

clusters <- tibble(ID=rownames(transform_pred$ind$coord),
                   cluster = clustering$cluster) |>
            separate("ID",c("DivisionNm","Year"),sep="_")

```

```{r}
withr::with_package("leaflet",
                    {
        
        df <- get_map(year=2016,
                      aggregation = "CED_NAME_2016",
                      filter_table = list_structure(year=2016),
                      use_cache = TRUE) |>
          select(CED_NAME_2016) |>
          left_join()
              
                      
                    })
```
